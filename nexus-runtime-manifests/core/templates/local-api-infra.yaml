---
{{- if ne .Values.global.cronApiVersion "" }}
apiVersion: {{ .Values.global.cronApiVersion }}
{{- else if (.Capabilities.APIVersions.Has "batch/v1beta1/CronJob") -}}
apiVersion: batch/v1beta1
{{- else if (.Capabilities.APIVersions.Has "batch/v1/CronJob") }}
apiVersion: batch/v1
{{- end }}
kind: CronJob
metadata:
  name: nexus-etcd-defrag
  namespace: {{ default  .Release.Namespace .Values.global.namespace }}
spec:
  successfulJobsHistoryLimit: 1
  failedJobsHistoryLimit: 1
  schedule: "0,30 * * * *"
  jobTemplate:
    spec:
      template:
        metadata:
          annotations:
            sidecar.istio.io/inject: "false"
        spec:
          serviceAccountName: default
          restartPolicy: OnFailure
          containers:
          - name: etcd-defrag
            image: {{.Values.global.registry}}/nexus-etcd-kubectl:latest
            imagePullPolicy: IfNotPresent
            command:
            - "/bin/bash"
            - "-c"
            - |
              set -euxo pipefail
              ETCDCTL_API=3 etcdctl --endpoints=nexus-etcd:2379 endpoint status --write-out=table
              ETCDCTL_API=3 etcdctl --endpoints=nexus-etcd:2379 defrag --cluster
              ETCDCTL_API=3 etcdctl --endpoints=nexus-etcd:2379 endpoint status --write-out=table
              echo "etcd defragmented successfully!"
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: nexus-k8scert-secret-permission
  namespace: {{ default  .Release.Namespace .Values.global.namespace }}
rules:
- apiGroups:
  - ""
  resources:
  - "secrets"
  verbs:
  - get
  - watch
  - list
  - create
  - delete
  - patch
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nexus-k8scerts-service-account
  namespace: {{ default  .Release.Namespace .Values.global.namespace }}
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: nexus-k8scert-create-secret-rbac
  namespace: {{ default  .Release.Namespace .Values.global.namespace }}
subjects:
- kind: ServiceAccount
  name: nexus-k8scerts-service-account
roleRef:
  kind: Role
  name: nexus-k8scert-secret-permission
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: batch/v1
kind: Job
metadata:
  name: nexus-k8scert-creation-job
  namespace: {{ default  .Release.Namespace .Values.global.namespace }}
  annotations:
    {{- template "argoJobHook" .}}
spec:
  template:
    metadata:
      annotations:
        "sidecar.istio.io/inject": "false"
    spec:
      serviceAccountName: nexus-k8scerts-service-account
      {{- if eq .Values.global.tainted true }}
      {{- template "tolerations" .}}
      {{- end }}
      containers:
      - name: k8scert-creation
        image: "{{.Values.global.registry}}/debugtools:latest"
        imagePullPolicy: IfNotPresent
        command:
        - "/bin/bash"
        - "-c"
        - |
          set -e
          openssl rand -out /root/.rnd -hex 256
          openssl genrsa -out /tmp/ca.key 2048
          openssl req -x509 -new -nodes -key /tmp/ca.key -subj "/CN=nexus-apiserver" -days 10000 -out /tmp/ca.crt
          if kubectl get secret nexus-customapi-ca -n $KUBERNETES_POD_NAMESPACE 1>&2>/dev/null; then \
            echo "Skipping Secret ${secret} creation on $KUBERNETES_POD_NAMESPACE as it already exists"
            exit 0
          else
            kubectl create secret generic nexus-customapi-ca --from-file=/tmp/ca.key --from-file=/tmp/ca.crt -n $KUBERNETES_POD_NAMESPACE --dry-run -o yaml | kubectl apply -f -
          fi
        env:
          - name: KUBERNETES_POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
      restartPolicy: Never
  backoffLimit: 4
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nexus-kube-apiserver
  namespace: {{ default  .Release.Namespace .Values.global.namespace }}
  labels:
    app: nexus-kube-apiserver
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nexus-kube-apiserver
  template:
    metadata:
      labels:
        app: nexus-kube-apiserver
    spec:
      {{- if eq .Values.global.tainted true }}
      {{- template "tolerations" .}}
      {{- end }}
      initContainers:
      - name: check-etcd-server
        image: "{{.Values.global.registry}}/debugtools:latest"
        imagePullPolicy: IfNotPresent
        command:
            - /bin/bash
            - -c
            - |
              #!/bin/bash
              URL="http://nexus-etcd:2379/health"
              max_retries=20
              counter=0
              while [[ $counter -lt $max_retries ]]; do
                    status=$(curl -s -o /dev/null -I -w "%{http_code}" -XGET $URL)
                    if [ $status == "200" ]; then
                        echo "$URL is reachable"
                        exit 0
                    else
                        counter=$((counter +1))
                        sleep 5
                        if [[ $counter -eq $max_retries ]]; then
                          exit 1
                        fi
                    fi
              done
      containers:
      - command:
        - kube-apiserver
        - --insecure-bind-address=0.0.0.0
        - --etcd-servers=http://nexus-etcd:2379
        - --service-account-key-file=/custom/k8s/certs/ca.crt
        - --service-cluster-ip-range=10.24.0.0/16
        - --cert-dir=/etc/kubernetes/certs
        - --endpoint-reconciler-type=none
        - --port=8080
        - --runtime-config=api/all=false,admissionregistration.k8s.io/v1=true,apiregistration.k8s.io/v1=true,v1=true,apiextensions.k8s.io/v1=true
        - --disable-admission-plugins=RuntimeClass,DefaultIngressClass,DefaultStorageClass,StorageObjectInUseProtection,Priority,ResourceQuota,PersistentVolumeClaimResize
        image: {{.Values.global.registry}}/k8s.gcr.io/kube-apiserver:v1.19.16
        imagePullPolicy: IfNotPresent
        ports:
          - containerPort: 8080
        env:
        - name: KUBERNETES_POD_NAMESPACE
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
        ## this is to fix tls certificate error in validation layer
        - name: GODEBUG
          value: x509ignoreCN=0
        name: kube-apiserver
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        livenessProbe:
          failureThreshold: 8
          httpGet:
            path: /healthz
            port: 8080
            scheme: HTTP
          initialDelaySeconds: 15
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 15
        {{- template "kube_apiserver_resources" .}}
        volumeMounts:
            - name: nexus-customapi-ca
              mountPath: "/custom/k8s/certs"
              readOnly: true
      restartPolicy: Always
      securityContext: {}
      volumes:
      - name: nexus-customapi-ca
        secret:
            secretName: nexus-customapi-ca
---
apiVersion: v1
kind: Service
metadata:
  name: nexus-apiserver
  namespace: {{ default  .Release.Namespace .Values.global.namespace }}
spec:
  type: ClusterIP
  ports:
    - protocol: TCP
      name: http
      port: 8080
      targetPort: 8080
    - protocol: TCP
      port: 6443
      name: https
      targetPort: 6443
  selector:
      app: nexus-kube-apiserver
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nexus-kube-controllermanager
  namespace: {{ default  .Release.Namespace .Values.global.namespace }}
spec:
  replicas: 1
  selector:
    matchLabels:
      name: nexus-kube-controllermanager
  template:
    metadata:
      labels:
        name: nexus-kube-controllermanager
    spec:
      {{- if eq .Values.global.tainted true }}
      {{- template "tolerations" .}}
      {{- end }}
      initContainers:
      - name: check-etcd-server
        image: "{{.Values.global.registry}}/debugtools:latest"
        imagePullPolicy: IfNotPresent
        command:
            - /bin/bash
            - -c
            - |
              #!/bin/bash
              URL="http://nexus-apiserver:8080/version"
              max_retries=20
              counter=0
              while [[ $counter -lt $max_retries ]]; do
                    status=$(curl -s -o /dev/null -I -w "%{http_code}" -XGET $URL)
                    if [ $status == "200" ]; then
                        echo "$URL is reachable"
                        exit 0
                    else
                        counter=$((counter +1))
                        sleep 5
                        if [[ $counter -eq $max_retries ]]; then
                          exit 1
                        fi
                    fi
              done
      containers:
      - command:
        - kube-controller-manager
        - --service-account-private-key-file=/custom/k8s/certs/ca.key
        - --leader-elect=false
        - --master=nexus-apiserver:8080
        - --use-service-account-credentials=true
        - --authentication-skip-lookup=true
        image: {{.Values.global.registry}}/k8s.gcr.io/kube-controller-manager:v1.19.0
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 8
          httpGet:
            path: /healthz
            port: 10257
            scheme: HTTPS
          initialDelaySeconds: 15
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 15
        name: kube-controllermanager
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        volumeMounts:
            - name: nexus-customapi-ca
              mountPath: "/custom/k8s/certs"
              readOnly: true
        {{- template "kube_controllermanager_resources" .}}
      restartPolicy: Always
      securityContext: {}
      volumes:
      - name: nexus-customapi-ca
        secret:
            secretName: nexus-customapi-ca
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nexus-proxy-container
  namespace: {{ default  .Release.Namespace .Values.global.namespace }}
  labels:
    app: nexus-proxy-container
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nexus-proxy-container
  template:
    metadata:
      labels:
        app: nexus-proxy-container
    spec:
      {{- if eq .Values.global.tainted true }}
      {{- template "tolerations" .}}
      {{- end }}
      containers:
      - name: proxy-container
        image: "{{.Values.global.registry}}/debugtools:latest"
        command: [ "kubectl","--server=http://nexus-apiserver:8080","proxy","--address=0.0.0.0","--disable-filter=true","--v=1" ]
        ports:
          - containerPort: 8001
        resources:
          requests:
            cpu: 100m
            memory: 200Mi
          limits:
            cpu: 100m
            memory: 200Mi
        imagePullPolicy: IfNotPresent
---
# removing the nexus proxy container deployment and keeping the service as it is
# retaining this due to the reason that multiple existing jobs refer to proxy container service
apiVersion: v1
kind: Service
metadata:
  name: nexus-proxy-container
  namespace: {{ default  .Release.Namespace .Values.global.namespace }}
spec:
  ports:
    - protocol: TCP
      name: http
      port: 80
      targetPort: 8001
  selector:
      app: nexus-proxy-container
